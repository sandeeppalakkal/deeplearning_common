{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_1a",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "zjyx9S-Ccoyy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Matrix** **Multiplication**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Input - 2 matrices of compatible sizes ('m1', 'm2')\n",
        "\n",
        "Output - Sum of elements of matrix obtained by multiplying 'm1', 'm2'"
      ]
    },
    {
      "metadata": {
        "id": "_2FGRgOtzmNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "from google.colab import files\n",
        "import cv2\n",
        "\n",
        "def multiply_matrices(m1, m2):\n",
        "    if not (m1.shape == m2.shape):\n",
        "        raise Exception('Matrices are not of the same dimenstion', m1.shape, m2.shape, 'are not compatible')\n",
        "    prod = m1*m2\n",
        "    return np.sum(prod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrOT8lU6z_F4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Fully Connected Layer**\n",
        "\n",
        "---\n",
        "Neurons in a fully connected layer have full connections to all activations in the previous layer. Their activations can hence be computed with a matrix multiplication followed by a bias offset. \n",
        "\n",
        "Input - Input matrix [C x W x H] , weights [(C*W*H) x M] , bias [M x 1]\n",
        "\n",
        "Output - Output of FC Layer [1 x M]"
      ]
    },
    {
      "metadata": {
        "id": "Dv8RPJF-oq8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def flatten(ip):\n",
        "  out = None\n",
        "  C, W, H = ip.shape\n",
        "  reshaped_input = ip.reshape((1, int(C*W*H)))\n",
        "  return reshaped_input  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aBkuLrIazz5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fullyconnected(ip, weights, bias=None):\n",
        "  if bias is None:\n",
        "    out = np.dot(ip, weights)\n",
        "  else:\n",
        "    out = np.dot(ip, weights) + bias\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwWk-IMFiHvH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Activation Layers**\n",
        "\n",
        "---\n",
        "\n",
        "**ReLU (Rectified Linear Unit)**\n",
        "\n",
        "ReLU layer will apply an elementwise activation function 'max(0,x)'  i.e. thresholding at zero. This leaves the size of the volume unchanged.\n",
        "\n",
        "![RELU](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Softmax Activation**\n",
        "\n",
        "The softmax function squashes the outputs of each unit to be between 0 and 1 and it also divides each output such that the total sum of the outputs is equal to 1.\n",
        "The output of the softmax function is equivalent to a categorical probability distribution, it tells you the probability that any of the classes are true.\n",
        "\n",
        "![Softmax](https://cloud.githubusercontent.com/assets/14886380/22743247/9eb7c856-ee54-11e6-98ca-a7e03120b1f8.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_5ufcgkVz0zn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Activation:\n",
        "    ## act_type: 0 = ReLU\n",
        "    ##           1 = Softmax\n",
        "    ##           2 = Sigmoid\n",
        "    ## ip_type: 0 = ReLU for conv layer\n",
        "    ## ip_type: 1 = ReLU for dense layer\n",
        "    def __init__(self, ip, act_type, ip_type=0):\n",
        "        self.ip = ip\n",
        "        self.act_type = act_type\n",
        "        self.ip_type = ip_type\n",
        "    \n",
        "    def relu(self):\n",
        "      if (self.ip_type == 0):\n",
        "        input = self.ip  \n",
        "        relu_out = np.zeros(input.shape)  \n",
        "        for map_num in range(input.shape[-1]):  \n",
        "            for r in np.arange(0,input.shape[0]):  \n",
        "                for c in np.arange(0, input.shape[1]):\n",
        "                    if input[r, c, map_num] > 0:\n",
        "                      relu_out[r, c, map_num] = input[r, c, map_num]\n",
        "        return relu_out \n",
        "      else:\n",
        "        input = self.ip\n",
        "        relu_out = np.zeros(input.shape)        \n",
        "        for r in np.arange(0,input.shape[0]):  \n",
        "          for c in np.arange(0, input.shape[1]):\n",
        "            if input[r, c] > 0:\n",
        "              relu_out[r, c] = input[r, c]\n",
        "        return relu_out\n",
        "\n",
        "    def softmax(self): \n",
        "        out = np.exp(self.ip) \n",
        "        return out / np.sum(out)\n",
        "\n",
        "    def forward_pass(self):\n",
        "        if (self.act_type == 0):\n",
        "            return self.relu()\n",
        "        if (self.act_type == 1):\n",
        "            return self.softmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIpBqxx8YA9q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Convolution Layer**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Convolution layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. \n",
        "\n",
        "\n",
        "![Convolution](https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif)\n",
        "\n",
        "# **Zero padding**\n",
        "\n",
        "---\n",
        "\n",
        "Sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes\n",
        "\n",
        "\n",
        "![Zero padding](data:image/png;base64,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)\n",
        "\n",
        "# **Stride**\n",
        "\n",
        "---\n",
        "\n",
        "The stride specifies the value with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.\n",
        "\n",
        "**In the gif below, stride is 2**\n",
        "\n",
        "![alt text](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif)"
      ]
    },
    {
      "metadata": {
        "id": "yfbMC608riXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Pooling**\n",
        "\n",
        "Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation. The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations.\n",
        "\n",
        "![alt text](https://www.cntk.ai/jup/c103d_max_pooling.gif)"
      ]
    },
    {
      "metadata": {
        "id": "MzTPQQFaamf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pooling(ip, pool_size=2, stride=2):  \n",
        "  num_channels, ip_size, _ = ip.shape\n",
        "  #out_size = ip_size - pool_size // stride\n",
        "  pool_out = np.zeros((num_channels, (ip_size - pool_size)//stride + 1, (ip_size - pool_size)//stride + 1))\n",
        "  for map_num in range(num_channels):\n",
        "    r2 = 0\n",
        "    for r in np.arange(0, ip_size - pool_size + 1, stride):  \n",
        "      c2 = 0\n",
        "      for c in np.arange(0, ip_size - pool_size + 1, stride):\n",
        "        for row in ip[map_num][r:r+pool_size]:\n",
        "          for column in row[c:c+pool_size]:\n",
        "            if (pool_out[map_num, r2, c2] < column):\n",
        "              pool_out[map_num, r2, c2] = column\n",
        "        c2 = c2 + 1  \n",
        "      r2 = r2 +1  \n",
        "  return pool_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6QUKvSa9HK8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Pre Trained Model Weights\n",
        "\n",
        "Load pre trained model weights, trained on CIFAR 10 dataset"
      ]
    },
    {
      "metadata": {
        "id": "VdZAcPqXFotc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def uploader():\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('user uploaded file {name} with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "06JqhahZG3Wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loader(input_weights_file):\n",
        "  weights = pk.load(open(input_weights_file, 'rb'))\n",
        "  n_weights = {}\n",
        "  for layer_name in weights:\n",
        "    w = weights[layer_name]\n",
        "    if not (len(w) == 0):\n",
        "      if 'conv' in layer_name:\n",
        "        n_weights[layer_name] = np.array(w[0]).T   #np.rollaxis(np.rollaxis(np.array(w[0]), 3, 0), 3, 1)\n",
        "      if 'dense' in layer_name:\n",
        "        n_weights[layer_name] = w[0]\n",
        "  return n_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdEv1ohkX-Kl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Model Definition**\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/IshaanMudgal/IITB-DL-Workshop/master/Capture.PNG)"
      ]
    },
    {
      "metadata": {
        "id": "A7nVBtCe5D1k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "\n",
        "data = unpickle('cifar-10-batches-py/data_batch_1')\n",
        "data.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBbz897e3QTR",
        "colab_type": "code",
        "outputId": "4eeb136d-c0c6-4cbc-d9fd-252d2659e892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "def extractImagesAndLabels(path, file):\n",
        "    f = open(path+file, 'rb')\n",
        "    dicts = pickle.load(f, encoding='bytes')\n",
        "    images = dicts[b'data']\n",
        "    images = np.reshape(images, (10000, 3, 32, 32))\n",
        "    labels = dicts[b'labels']\n",
        "    imagearray = np.array(images)\n",
        "    labelarray = np.array(labels)\n",
        "    return imagearray, labelarray\n",
        "\n",
        "def extractCategories(path, file):\n",
        "    f = open(path+file, 'rb')\n",
        "    dicts = pickle.load(f)\n",
        "    return dicts['label_names']\n",
        "\n",
        "def saveCifarImage(array, path, file):\n",
        "    # array is 3x32x32. cv2 needs 32x32x3\n",
        "    array = array.transpose(1,2,0)\n",
        "    # array is RGB. cv2 needs BGR\n",
        "    array = cv2.cvtColor(array, cv2.COLOR_RGB2BGR)\n",
        "    # save to PNG file\n",
        "    return cv2.imwrite(path+file+\".png\", array)\n",
        "\n",
        "imgarray, lblarray = extractImagesAndLabels(\"cifar-10-batches-py/\", \"data_batch_1\")\n",
        "print(imgarray.shape)\n",
        "print(lblarray.shape)\n",
        "\n",
        "categories = extractCategories(\"cifar-10-batches-py/\", \"batches.meta\")\n",
        "\n",
        "cats = []\n",
        "for i in range(0,10):\n",
        "    saveCifarImage(imgarray[i], \"./cifar10_images/\", \"image\"+(str)(i))\n",
        "    category = np.array(lblarray[i])\n",
        "    category = (int(category))\n",
        "    cats.append(categories[category])\n",
        "print(cats)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 3, 32, 32)\n",
            "(10000,)\n",
            "['frog', 'truck', 'truck', 'deer', 'automobile', 'automobile', 'bird', 'horse', 'ship', 'cat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XdmVixw62ITX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "#data = unpickle('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzbDX4oG0ag1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "(X_train,y_train), (X_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "im0RIiKvz3Dm",
        "colab_type": "code",
        "outputId": "d6c024ee-61ec-4660-84aa-def7f55d5c32",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "end_points = {}\n",
        "NUM_CLASSES = 10\n",
        "uploader()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-19451bc5-d641-448a-a9fd-840f81f7ee28\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-19451bc5-d641-448a-a9fd-840f81f7ee28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving CIFAR_weights_rolled to CIFAR_weights_rolled\n",
            "user uploaded file CIFAR_weights_rolled with length 6705530 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CxJt5QgXTUck",
        "colab_type": "code",
        "outputId": "c193e1ba-2d8a-413d-d998-5fc4826c4a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "filename = 'CIFAR_weights_rolled'\n",
        "m_weights = loader(filename)\n",
        "\n",
        "### Load preweights for the network ###\n",
        "convlayer1_kernels = m_weights['conv2d_1']\n",
        "convlayer2_kernels = m_weights['conv2d_2']\n",
        "convlayer3_kernels = m_weights['conv2d_3']\n",
        "convlayer4_kernels = m_weights['conv2d_4']\n",
        "denselayer1_weights = np.array(m_weights['dense_1'])\n",
        "denselayer2_weights = np.array(m_weights['dense_2'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 32, 3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D0_xqL-zzr1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLayer():\n",
        "    def __init__(self, layer_type, ip, kernels, stride=1, padding=1):\n",
        "        self.layer_type = layer_type\n",
        "        self.ip = ip\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        self.kernels = kernels\n",
        "        return\n",
        "    \n",
        "    def _conv_maps(self, cmap, kernel):\n",
        "        ip_size, ip_size = cmap.shape\n",
        "        kernel_size, kernel_size = kernel.shape\n",
        "        output_size = int((ip_size - kernel_size + self.padding)/self.stride)\n",
        "        #### Create a new padded input map\n",
        "        padded_size = ip_size + self.padding\n",
        "        cmap_padded = np.zeros([padded_size, padded_size])\n",
        "        for col in range(padded_size):\n",
        "            for row in range(padded_size):\n",
        "                if (row >= ip_size) or (col >= ip_size):\n",
        "                    break\n",
        "                cmap_padded[row + self.padding//2, col + self.padding//2] = cmap[row, col]\n",
        "\n",
        "        #### Compute the output map\n",
        "        output_map = np.zeros([ip_size, ip_size])\n",
        "        try:\n",
        "            for c in range(ip_size):\n",
        "                for r in range(ip_size):\n",
        "                    m1 = cmap_padded[c:c+(kernel_size - self.padding//2 + 1), r:r + (kernel_size - self.padding//2 + 1)]\n",
        "                    output_map[c][r] = multiply_matrices(m1, kernel)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "        return output_map\n",
        "      \n",
        "    def _conv_3d_maps(self, cmap, kernel):\n",
        "      num_channels, ip_size, ip_size = cmap.shape\n",
        "      num_kernel_channels, kernel_size, kernel_size = kernel.shape\n",
        "      if not (num_channels == num_kernel_channels):\n",
        "        print(\"Mismatch in number of channels of kernel and input image\")\n",
        "      output_size = int((ip_size - kernel_size + self.padding)/self.stride)\n",
        "      #### Create a new padded input map\n",
        "      padded_size = ip_size + self.padding\n",
        "      cmap_padded = np.zeros([num_channels, padded_size, padded_size])\n",
        "      for c in range(num_channels):\n",
        "        for col in range(padded_size):\n",
        "            for row in range(padded_size):\n",
        "                if (row >= ip_size) or (col >= ip_size):\n",
        "                    break\n",
        "                cmap_padded[c, row + self.padding//2, col + self.padding//2] = cmap[c, row, col]\n",
        "\n",
        "      #### Compute the output map\n",
        "      output_size, output_size = (padded_size - kernel_size)//self.stride + 1, (padded_size - kernel_size)//self.stride + 1\n",
        "      output_map_3d = np.zeros([output_size, output_size])\n",
        "      stride = self.stride\n",
        "      try:\n",
        "          cmap_iter_row = kernel_size // 2          \n",
        "          out_col, out_row = 0, 0\n",
        "          while (out_row < output_size):\n",
        "              if (cmap_iter_row + kernel_size//2 + 1 > padded_size):\n",
        "                #print(\"BREAK1\")\n",
        "                break\n",
        "              out_col = 0\n",
        "              cmap_iter_col = kernel_size // 2 \n",
        "              while (out_col < output_size):                  \n",
        "                  if (cmap_iter_col + kernel_size//2 + 1 > padded_size):\n",
        "                    break\n",
        "                  m1 = cmap_padded[:, cmap_iter_row - kernel_size//2:cmap_iter_row + kernel_size//2 + 1, cmap_iter_col - kernel_size//2:cmap_iter_col + kernel_size//2 + 1]\n",
        "                  output_map_3d[out_row][out_col] = np.sum(multiply_matrices(m1, kernel))                 \n",
        "                  cmap_iter_col += stride                  \n",
        "                  out_col += 1\n",
        "              out_row += 1\n",
        "              cmap_iter_row += stride\n",
        "\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "          \n",
        "      return output_map_3d\n",
        "\n",
        "    def forward_pass(self):\n",
        "        this_input = self.ip\n",
        "        ip_depth, ip_size, ip_size = this_input.shape\n",
        "        num_kernels, kernel_depth, kernel_size, kernel_size = self.kernels.shape\n",
        "        outputs = []\n",
        "        for kernel_id in range(num_kernels):\n",
        "          out_map = np.zeros((ip_size, ip_size))\n",
        "          out_map = self._conv_3d_maps(this_input, self.kernels[kernel_id])\n",
        "          outputs.append(out_map)\n",
        "        return np.array(outputs)\n",
        "\n",
        "    def test(self):\n",
        "        cmap = np.ones([5, 10, 10])\n",
        "        print(cmap.shape)\n",
        "        self.ip = cmap\n",
        "        out = self.forward_pass()\n",
        "        print(out[0].shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SF-Njnw77SM8",
        "colab_type": "code",
        "outputId": "7b0ca13e-682b-4fb4-df0f-ac2ecb106bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "inputs = Image.open('cifar10_images/image0.png')\n",
        "inputs = np.array(inputs)\n",
        "inputs = inputs.T #np.rollaxis(inputs, 2, 0)\n",
        "\n",
        "inputs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "_JPlWdIFS5V_",
        "colab_type": "code",
        "outputId": "305b412a-14af-4e35-9672-bb99c5801d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer1 #####\n",
        "layer1_stride = 1\n",
        "layer1_padding = 2\n",
        "layer1 = ConvLayer(1, inputs, convlayer1_kernels, layer1_stride, layer1_padding)\n",
        "layer1_out = layer1.forward_pass()\n",
        "end_points['convlayer1'] = layer1_out\n",
        "print(\"convlayer1 output ready\")\n",
        "\n",
        "##### Act1 #####\n",
        "act1_inputs = layer1_out\n",
        "act1 = Activation(act1_inputs, 0)\n",
        "act1_outs = act1.forward_pass()\n",
        "end_points['act1'] = act1_outs\n",
        "print(act1_outs.shape)\n",
        "print(act1_outs[:, 11, 5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convlayer1 output ready\n",
            "(32, 32, 32)\n",
            "[26.12792886 27.17737738  2.71886375 22.73427187  0.          3.63419392\n",
            " 10.92617407 71.60864685 14.19427808 26.34139935  9.59704561 15.31502198\n",
            " 33.4791548  29.86943034  0.         47.80157814 33.54173714 37.41098969\n",
            "  3.40548129  2.12105108 13.85435526 16.35328179  8.06284727 10.44482682\n",
            " 18.28303231  0.          0.82307874  0.         12.8475696   0.\n",
            " 12.48848038  0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "etCo_00GTKEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer2 #####\n",
        "layer2_inputs = act1_outs\n",
        "layer2_stride = 1\n",
        "layer2_padding = 0\n",
        "layer2 = ConvLayer(2, layer2_inputs, convlayer2_kernels, layer2_stride, layer2_padding)\n",
        "layer2_out = layer2.forward_pass()\n",
        "end_points['convlayer2'] = layer2_out\n",
        "\n",
        "##### Act2 #####\n",
        "act2_inputs = layer2_out\n",
        "act2 = Activation(act2_inputs, 0)\n",
        "act2_outs = act2.forward_pass()\n",
        "end_points['act2'] = act2_outs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1M1-f2DkaBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### MaxPool #####\n",
        "pool_inputs = act2_outs\n",
        "pool_outs = pooling(pool_inputs, pool_size=2, stride=2)\n",
        "print(pool_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRlX9HExTEzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer3 #####\n",
        "layer3_inputs = pool_outs\n",
        "layer3_stride = 1\n",
        "layer3_padding = 2\n",
        "layer3 = ConvLayer(2, layer3_inputs, convlayer3_kernels, layer3_stride, layer3_padding)\n",
        "layer3_out = layer3.forward_pass()\n",
        "end_points['convlayer3'] = layer3_out\n",
        "print(\"conv3 outputs ready\")\n",
        "\n",
        "##### Act3 #####\n",
        "act3_inputs = layer3_out\n",
        "act3 = Activation(act3_inputs, 0)\n",
        "act3_outs = act3.forward_pass()\n",
        "end_points['act3'] = act3_outs\n",
        "print(act3_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SVHC53KRTFTa",
        "colab_type": "code",
        "outputId": "62def794-c387-4eab-c012-dee7205d34c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer4 #####\n",
        "layer4_inputs = act3_outs\n",
        "layer4_stride = 1\n",
        "layer4_padding = 2\n",
        "layer4 = ConvLayer(4, layer4_inputs, convlayer4_kernels, layer4_stride, layer4_padding)\n",
        "layer4_out = layer4.forward_pass()\n",
        "end_points['convlayer4'] = layer4_out\n",
        "print(\"conv4 outputs ready\")\n",
        "\n",
        "##### Act4 #####\n",
        "act4_inputs = layer4_out\n",
        "act4 = Activation(act4_inputs, 0)\n",
        "act4_outs = act4.forward_pass()\n",
        "end_points['act4'] = act4_outs\n",
        "print(act4_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv4 outputs ready\n",
            "(64, 15, 15)\n",
            "[  0.           0.         175.69071423   0.           0.\n",
            " 114.53115689  44.97442348   0.           0.          52.95552138\n",
            "  50.98536717   0.          96.13496836   0.          53.81752963\n",
            "   0.          53.85306116 114.69066805 143.97076769   0.\n",
            "   9.64679862   1.44705332   0.          31.04929598   0.\n",
            "  19.96903942   0.          87.18096282   7.61223217   0.\n",
            "  45.9275365    0.         100.88500155  26.49785512   0.\n",
            "   0.          63.62250246  44.14073104   0.         131.87034231\n",
            "   0.          23.20774273   0.           0.          22.56073487\n",
            "  60.8067447    0.           0.          91.9633625   53.35419854\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.          95.6159015    0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fob7w8FHTGfQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  uploader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3WUf6Troc7c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### MaxPool2 #####\n",
        "pool2_inputs = act4_outs\n",
        "pool2_outs = pooling(pool2_inputs, pool_size=2, stride=2)\n",
        "print(pool2_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZXGfxUsT2mg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flattened_out = flatten(pool2_outs.T)\n",
        "##### Dense 3 #####\n",
        "denselayer1_inputs = flattened_out\n",
        "denselayer1_outs = fullyconnected(denselayer1_inputs, denselayer1_weights)\n",
        "## Normalization\n",
        "#denselayer1_outs = denselayer1_outs/np.max(denselayer1_outs)\n",
        "end_points['FC'] = denselayer1_outs\n",
        "print(denselayer1_inputs.shape)\n",
        "\n",
        "##### Act5 #####\n",
        "act5_inputs = denselayer1_outs\n",
        "act5 = Activation(act5_inputs, 0, 1)\n",
        "act5_outs = act5.forward_pass()\n",
        "end_points['act5'] = act5_outs\n",
        "print(act5_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlC-6lB5IXD9",
        "colab_type": "code",
        "outputId": "bfe9f4b7-15e2-44ca-bec1-1667437687c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "##### Dense 4 #####\n",
        "denselayer2_inputs = act5_outs\n",
        "denselayer2_outs = fullyconnected(denselayer2_inputs, denselayer2_weights)\n",
        "## Normalization\n",
        "#denselayer2_outs = denselayer2_outs/np.max(denselayer2_outs)\n",
        "end_points['FC'] = denselayer2_outs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1873.16151632 -2642.79908102   -17.58973522   306.06752917\n",
            "     83.59143845    69.08362883  1897.53372175  -424.51099236\n",
            "  -2821.61247977 -3115.48194229]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fwreyOKjIYak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### final Activation #####\n",
        "print(np.mean(denselayer2_outs))\n",
        "print(np.var(denselayer2_outs))\n",
        "#finalact_inputs = (denselayer2_outs - np.mean(denselayer2_outs))/np.var(denselayer2_outs)\n",
        "finalact_inputs = denselayer2_outs/np.max(denselayer2_outs)\n",
        "finalact = Activation(finalact_inputs, 1)\n",
        "finalact_outs = finalact.forward_pass()\n",
        "end_points['finalact'] = finalact_outs\n",
        "\n",
        "print(end_points['finalact'])\n",
        "print(np.sum(finalact_outs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVUXQvjawvVG",
        "colab_type": "code",
        "outputId": "dece0c69-5603-4949-b8f2-6345bcd6c4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "index = np.argmax(finalact_outs)\n",
        "predicted_class = class_names[index]\n",
        "print(predicted_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frog\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}