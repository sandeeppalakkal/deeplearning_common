{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_1a",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "R2gsEmJz3Rd9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network Framework \n",
        "We'll try to build the following ConvNet by the end of this session\n",
        "\n",
        "![Architecture](https://github.com/IshaanMudgal/IITB-DL-Workshop/blob/master/sess1_res/Model_img_2.JPG?raw=true)\n",
        "\n",
        "**Components:**\n",
        "1. Fully Connected / Dense\n",
        "2. Activation\n",
        "3. Convolution\n",
        "4. Pooling"
      ]
    },
    {
      "metadata": {
        "id": "zjyx9S-Ccoyy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Utilities**\n",
        "\n",
        "---\n",
        "**Matrix Multiplication**:\n",
        "\n",
        "    Input - 2 matrices of compatible sizes ('m1', 'm2')\n",
        "\n",
        "    Output - Sum of elements of matrix obtained by multiplying 'm1', 'm2'\n",
        "   \n",
        "**Uploader**:\n",
        "  To upload files from local machine"
      ]
    },
    {
      "metadata": {
        "id": "_2FGRgOtzmNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "from google.colab import files\n",
        "import cv2\n",
        "\n",
        "def multiply_matrices(m1, m2):\n",
        "    if not (m1.shape == m2.shape):\n",
        "        raise Exception('Matrices are not of the same dimenstion', m1.shape, m2.shape, 'are not compatible')\n",
        "    prod = m1*m2\n",
        "    return np.sum(prod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdZAcPqXFotc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def uploader():\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('user uploaded file {name} with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrOT8lU6z_F4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Fully Connected / Dense Layer**\n",
        "\n",
        "---\n",
        "Neurons in a fully connected layer have full connections to all activations in the previous layer.\n",
        "Their activations can hence be computed with a matrix multiplication followed by a bias offset. \n",
        "\n",
        "Input - Input matrix [1 x L] , weights [L x N] , bias [1 x N]\n",
        "\n",
        "Output - Output of FC Layer [1 x N]\n",
        "\n",
        "\n",
        "![FC_Layer](https://github.com/IshaanMudgal/IITB-DL-Workshop/blob/master/sess1_res/tfdl_0401.png?raw=true)![equation](https://github.com/IshaanMudgal/IITB-DL-Workshop/blob/master/sess1_res/equation_fc.png?raw=true)\n",
        "\n",
        "\n",
        "\n",
        "https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0401.png"
      ]
    },
    {
      "metadata": {
        "id": "aBkuLrIazz5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### Output = W*X + bias ######\n",
        "def fullyconnected(ip, weights, bias=None):\n",
        "  if bias is None:\n",
        "    out = np.dot(ip, weights)\n",
        "  else:\n",
        "    out = np.dot(ip, weights) + bias\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zwWk-IMFiHvH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Activation Layers**\n",
        "\n",
        "---\n",
        "An activation fucntion decides whether a nueron should be fired or not.\n",
        "\n",
        "**ReLU (Rectified Linear Unit)**\n",
        "\n",
        "ReLU layer will apply an elementwise activation function 'max(0,x)'  i.e. thresholding at zero. This leaves the size of the volume unchanged.\n",
        "\n",
        "![RELU](https://cdn-images-1.medium.com/max/937/1*oePAhrm74RNnNEolprmTaQ.png)\n",
        "\n",
        "*Source - https://cdn-images-1.medium.com/max/937/1oePAhrm74RNnNEolprmTaQ.png* \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Softmax Activation**\n",
        "\n",
        "The softmax function squashes the outputs of each unit to be between 0 and 1 and it also divides each output such that the total sum of the outputs is equal to 1.\n",
        "The output of the softmax function is equivalent to a categorical probability distribution, it tells you the probability that any of the classes are true.\n",
        "\n",
        "![Softmax](https://cloud.githubusercontent.com/assets/14886380/22743247/9eb7c856-ee54-11e6-98ca-a7e03120b1f8.png)\n",
        "\n",
        "*Source - https://cloud.githubusercontent.com/assets/14886380/22743247/9eb7c856-ee54-11e6-98ca-a7e03120b1f8.png* \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_5ufcgkVz0zn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Activation:\n",
        "    ## act_type: 0 = ReLU\n",
        "    ##           1 = Softmax\n",
        "    ##\n",
        "    ## ip_type: 0 = for ReLU after conv layer\n",
        "    ## ip_type: 1 = for ReLU after dense layer\n",
        "    def __init__(self, ip, act_type, ip_type=0):\n",
        "        self.ip = ip\n",
        "        self.act_type = act_type\n",
        "        self.ip_type = ip_type\n",
        "    \n",
        "    def relu(self):\n",
        "      ###### ReLU for Convolution ##########\n",
        "      if (self.ip_type == 0):\n",
        "        input = self.ip  \n",
        "        num_channels, input_size, _ = input.shape\n",
        "        ### Placeholder for output\n",
        "        relu_out = np.zeros([num_channels, input_size, input_size])  \n",
        "        \n",
        "        for map_id in range(num_channels):  \n",
        "            for r in np.arange(0, input_size):  \n",
        "                for c in np.arange(0, input_size):\n",
        "                  ##### TODO : Fill the placeholder with relu outputs ######\n",
        "                  ##########################################################\n",
        "                 \n",
        "        return relu_out \n",
        "      ###### ReLU for Dense layer ##########\n",
        "      else:\n",
        "        input = self.ip\n",
        "        relu_out = np.zeros(input.shape)        \n",
        "        for r in np.arange(0,input.shape[0]):  \n",
        "          for c in np.arange(0, input.shape[1]):\n",
        "            if input[r, c] > 0:\n",
        "              relu_out[r, c] = input[r, c]\n",
        "        return relu_out\n",
        "\n",
        "    def softmax(self):\n",
        "        inputs = self.ip\n",
        "        out = np.exp(inputs - np.max(inputs)) \n",
        "        return out / np.sum(out)\n",
        "\n",
        "    def forward_pass(self):\n",
        "        if (self.act_type == 0):\n",
        "            return self.relu()\n",
        "        if (self.act_type == 1):\n",
        "            return self.softmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIpBqxx8YA9q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Convolution Layer**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Convolution layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. \n",
        "\n",
        "\n",
        "![Convolution](https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif)![alt text](https://github.com/IshaanMudgal/IITB-DL-Workshop/blob/master/sess1_res/kernel_conv_2.JPG?raw=true)\n",
        "\n",
        "*Source - https://media.giphy.com/media/i4NjAwytgIRDW/giphy.gif*\n",
        "\n",
        "*Example:*\n",
        "![Edge Detection](https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/03/convolution.png)\n",
        "\n",
        "*Source: https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/03/convolution.png*\n",
        "\n",
        "# **Zero padding**\n",
        "\n",
        "---\n",
        "\n",
        "Sometimes it will be convenient to pad the input volume with zeros around the border. The size of this zero-padding is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes\n",
        "\n",
        "\n",
        "![Zero padding](data:image/png;base64,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)\n",
        "\n",
        "# **Stride**\n",
        "\n",
        "---\n",
        "\n",
        "The stride specifies the value with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.\n",
        "\n",
        "**In the gif below, stride is 2**\n",
        "\n",
        "![alt text](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif)\n",
        "\n",
        "*Source - http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif*\n",
        "#Convolution Output Size\n",
        "O = ((I - K + 2*P)/S) + 1"
      ]
    },
    {
      "metadata": {
        "id": "D0_xqL-zzr1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvLayer():\n",
        "    def __init__(self, ip, kernels, stride=1, padding=1):\n",
        "        self.ip = ip\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        self.kernels = kernels\n",
        "        return\n",
        "    \n",
        "    ############## Convolution 3d maps with 3d kernels ################\n",
        "    def _conv_3d_maps(self, cmap, kernel):\n",
        "      num_channels, ip_size, ip_size = cmap.shape\n",
        "      num_kernel_channels, kernel_size, kernel_size = kernel.shape\n",
        "      if not (num_channels == num_kernel_channels):\n",
        "        print(\"Mismatch in number of channels of kernel and input image\")\n",
        "        \n",
        "      padding_length = self.padding  \n",
        "      stride = self.stride\n",
        "      \n",
        "      ###########################################################################################################\n",
        "      ############################          Create a new padded input map       #################################\n",
        "      ###########################################################################################################\n",
        "      \n",
        "      padded_size = ip_size + 2*padding_length\n",
        "      cmap_padded = np.zeros([num_channels, padded_size, padded_size])\n",
        "      for c in range(num_channels):\n",
        "        for col in range(padded_size):\n",
        "            for row in range(padded_size):\n",
        "                if (row >= ip_size) or (col >= ip_size):\n",
        "                    break\n",
        "                ###### TODO : Fill the 'cmap_padded' placeholder to create a padded input map #######\n",
        "                #####################################################################################\n",
        "                \n",
        "      ###########################################################################################################\n",
        "      ###############      Compute the output map after convolving with the kernel filters    ###################\n",
        "      ###########################################################################################################\n",
        "\n",
        "      ##### TODO : Fill in the output size ######\n",
        "      output_size = ###\n",
        "      ###########################################\n",
        "      \n",
        "      ############# Output Placeholder #############\n",
        "      output_map_3d = np.zeros([output_size, output_size])\n",
        "      try:\n",
        "          cmap_iter_row = kernel_size // 2          \n",
        "          out_col, out_row = 0, 0\n",
        "          while (out_row < output_size):\n",
        "              if (cmap_iter_row + kernel_size//2 + 1 > padded_size):\n",
        "                break\n",
        "              out_col = 0\n",
        "              cmap_iter_col = kernel_size // 2 \n",
        "              while (out_col < output_size):                  \n",
        "                  if (cmap_iter_col + kernel_size//2 + 1 > padded_size):\n",
        "                    break\n",
        "                  m1 = cmap_padded[:, cmap_iter_row - kernel_size//2:cmap_iter_row + kernel_size//2 + 1, cmap_iter_col - kernel_size//2:cmap_iter_col + kernel_size//2 + 1]\n",
        "                  output_map_3d[out_row][out_col] = np.sum(multiply_matrices(m1, kernel))\n",
        "                  cmap_iter_col += stride     \n",
        "                  out_col += 1\n",
        "              out_row += 1\n",
        "              cmap_iter_row += stride\n",
        "\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "          \n",
        "      #### Return the convolved output ####\n",
        "      return output_map_3d\n",
        "\n",
        "    def forward_pass(self):\n",
        "        this_input = self.ip\n",
        "        ip_depth, ip_size, ip_size = this_input.shape\n",
        "        num_kernels, kernel_depth, kernel_size, kernel_size = self.kernels.shape\n",
        "        outputs = []\n",
        "        for kernel_id in range(num_kernels):\n",
        "          out_map = np.zeros((ip_size, ip_size))\n",
        "          out_map = self._conv_3d_maps(this_input, self.kernels[kernel_id])\n",
        "          outputs.append(out_map)\n",
        "        return np.array(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YrijVEIuQM6P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Flatten Layer**\n",
        "\n",
        "Output of convolution layers will be a 3-D feature map. \n",
        "If a dense/fullyconnected layer follows, then a reshape of the 3-D feature map is required (this operation is called flattening) \n",
        "\n",
        "![alt text](https://github.com/IshaanMudgal/IITB-DL-Workshop/blob/master/sess1_res/dDYphPB.png?raw=true)\n",
        "\n",
        "*Source:https://i1.wp.com/i.imgur.com/dDYphPB.png?zoom=1.25&resize=461%2C380&ssl=1*"
      ]
    },
    {
      "metadata": {
        "id": "Dv8RPJF-oq8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## To be used before calling Dense/FC layer so that the 3d input is converted to a 1d vector\n",
        "def flatten(ip):\n",
        "  out = None\n",
        "  C, W, H = ip.shape\n",
        "  reshaped_input = ip.reshape((1, int(C*W*H)))\n",
        "  return reshaped_input  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yfbMC608riXC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Pooling**\n",
        "\n",
        "Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. The Pooling Layer operates independently on every depth slice of the input and resizes it spatially, using the MAX operation. The most common form is a pooling layer with filters of size 2x2 applied with a stride of 2 downsamples every depth slice in the input by 2 along both width and height, discarding 75% of the activations.\n",
        "\n",
        "![alt text](https://www.cntk.ai/jup/c103d_max_pooling.gif)\n",
        "\n",
        "*Source - https://www.cntk.ai/jup/c103d_max_pooling.gif*"
      ]
    },
    {
      "metadata": {
        "id": "MzTPQQFaamf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pooling(ip, pool_size=2, stride=2): \n",
        "  num_channels, ip_size, _ = ip.shape\n",
        "  out_size = (ip_size - pool_size)//stride + 1\n",
        "  \n",
        "  ######## Placeholder for Pooled output ########\n",
        "  pool_out = np.zeros((num_channels, out_size, out_size))\n",
        "  \n",
        "  for map_num in range(num_channels):\n",
        "    output_row = 0\n",
        "    for row in np.arange(0, ip_size - pool_size + 1, stride):  \n",
        "      output_col = 0\n",
        "      for column in np.arange(0, ip_size - pool_size + 1, stride):\n",
        "        #######  TODO : Find the Max of input section from [row to row + pool_size, column to column + pool_size] #######\n",
        "        #################################################################################################################\n",
        "        output_col = output_col + 1\n",
        "      output_row = output_row + 1\n",
        "  return pool_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cdEv1ohkX-Kl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Model Definition**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NqZ8NxdrylTt",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "5bedcd3f-35f8-4d2d-f9c6-48151793480f"
      },
      "cell_type": "code",
      "source": [
        "#### Upload Cifar10 dataset\n",
        "uploader()\n",
        "!tar -zxvf cifar10.tar.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3e8e7b04-83f2-4c2e-b5fd-08e33c05d6ce\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3e8e7b04-83f2-4c2e-b5fd-08e33c05d6ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cifar10 (1).tar.gz to cifar10 (1).tar.gz\n",
            "user uploaded file cifar10 (1).tar.gz with length 25662 bytes\n",
            "tar (child): cifar10.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SF-Njnw77SM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "0ba49db9-33a2-49f6-ed39-8575bfdea1b0"
      },
      "cell_type": "code",
      "source": [
        "####### Load image for inference ########\n",
        "from PIL import Image\n",
        "inputs = Image.open('cifar10_images/image0.png')\n",
        "########### Display Image #############\n",
        "inputs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJZElEQVR4nAXB2Y8dWX0A4LP8TtWp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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7F9219C0A400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "8w8AgmSAOrx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a627d65-9349-4804-e35e-a74becfa5b13"
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array(inputs)\n",
        "inputs = inputs.T\n",
        "inputs.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "im0RIiKvz3Dm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####### Dictionary to save all intermediate outputs ########\n",
        "end_points = {} \n",
        "\n",
        "####### Number of output classes in dataset ########\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOlg57fHie7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's test our implementation with random weights"
      ]
    },
    {
      "metadata": {
        "id": "095h6nGvveyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####### Initialize model weights with random data ######\n",
        "convlayer1_kernels  = np.random.random((32, 3, 3, 3))\n",
        "convlayer2_kernels  = np.random.random((64, 32, 3, 3))\n",
        "convlayer3_kernels  = np.random.random((64, 64, 3, 3))\n",
        "convlayer4_kernels  = np.random.random((64, 64, 3, 3))\n",
        "denselayer1_weights = np.random.random((3136, 512))\n",
        "denselayer2_weights = np.random.random((512, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JPlWdIFS5V_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########################################################################################################\n",
        "###############                      Adding layers to model                             ###################\n",
        "###########################################################################################################\n",
        "\n",
        "\n",
        "##### ConvLayer1 #####\n",
        "layer1_stride = 1\n",
        "layer1_padding = 1\n",
        "layer1 = ConvLayer(inputs, convlayer1_kernels, layer1_stride, layer1_padding)\n",
        "layer1_outs = layer1.forward_pass()\n",
        "end_points['convlayer1'] = layer1_outs\n",
        "\n",
        "##### Act1 #####\n",
        "act1_inputs = layer1_outs\n",
        "act1 = Activation(act1_inputs, 0)\n",
        "act1_outs = act1.forward_pass()\n",
        "end_points['act1'] = act1_outs\n",
        "print(\"Activation1 output shape:\", act1_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etCo_00GTKEb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer2 #####\n",
        "layer2_inputs = act1_outs\n",
        "layer2_stride = 1\n",
        "layer2_padding = 0\n",
        "layer2 = ConvLayer(layer2_inputs, convlayer2_kernels, layer2_stride, layer2_padding)\n",
        "layer2_out = layer2.forward_pass()\n",
        "end_points['convlayer2'] = layer2_out\n",
        "\n",
        "##### Act2 #####\n",
        "act2_inputs = layer2_out\n",
        "act2 = Activation(act2_inputs, 0)\n",
        "act2_outs = act2.forward_pass()\n",
        "end_points['act2'] = act2_outs\n",
        "print(\"Activation2 output shape:\", act2_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U1M1-f2DkaBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### MaxPool #####\n",
        "pool1_inputs = act2_outs\n",
        "pool1_outs = pooling(pool1_inputs, pool_size=2, stride=2)\n",
        "print(\"Pool1 output shape:\", pool1_outs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRlX9HExTEzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f275b474-95c4-4fb3-cc53-13da2c219ad0"
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer3 #####\n",
        "layer3_inputs = pool1_outs\n",
        "\n",
        "####### TODO : Declare a conv3 layer with parameters as in the above architecture #######\n",
        "########################################################################################\n",
        "\n",
        "end_points['convlayer3'] = layer3_out\n",
        "\n",
        "##### Act3 #####\n",
        "act3_inputs = layer3_out\n",
        "\n",
        "###### TODO : Declare activation3 layer #######\n",
        "\n",
        "end_points['act3'] = act3_outs\n",
        "print(\"Activation3 output shape:\", act3_outs.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv3 outputs ready\n",
            "(64, 15, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SVHC53KRTFTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "09ec7729-23de-46d8-91ed-3e49decfdefb"
      },
      "cell_type": "code",
      "source": [
        "##### ConvLayer4 #####\n",
        "layer4_inputs = act3_outs\n",
        "\n",
        "####### TODO : Declare conv4 layer with parameters as in the above architecture #######\n",
        "########################################################################################\n",
        "\n",
        "end_points['convlayer4'] = layer4_out\n",
        "\n",
        "##### Act4 #####\n",
        "act4_inputs = layer4_out\n",
        "\n",
        "###### TODO : Declare activation4 layer as in architecture #######\n",
        "\n",
        "end_points['act4'] = act4_outs\n",
        "print(\"Activation4 output shape:\", act4_outs.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv4 outputs ready\n",
            "(64, 15, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h3WUf6Troc7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d5c9a75-3b15-4e01-98c6-e51bb93c5c97"
      },
      "cell_type": "code",
      "source": [
        "#### MaxPool2 #####\n",
        "pool2_inputs = act4_outs\n",
        "\n",
        "###### TODO : Declare Max-Pool2 layer #######\n",
        "\n",
        "print(\"Pool2 output shape:\", pool2_outs.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 7, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PZXGfxUsT2mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1535cd24-76a7-452f-97bb-407961dd4817"
      },
      "cell_type": "code",
      "source": [
        "##### Flatten #####\n",
        "flattened_out = flatten(pool2_outs.T)\n",
        "\n",
        "##### Dense 3 #####\n",
        "denselayer1_inputs = flattened_out\n",
        "denselayer1_outs = fullyconnected(denselayer1_inputs, denselayer1_weights)\n",
        "end_points['FC'] = denselayer1_outs\n",
        "print(\"Flatten Output Shape:\", denselayer1_inputs.shape)\n",
        "\n",
        "##### Act5 #####\n",
        "act5_inputs = denselayer1_outs\n",
        "act5 = Activation(act5_inputs, 0, 1)\n",
        "act5_outs = act5.forward_pass()\n",
        "end_points['act5'] = act5_outs\n",
        "print(\"Activation5 output shape:\", act5_outs.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flatten Output Shape: (1, 3136)\n",
            "Activation5 output shape: (1, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LlC-6lB5IXD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c1d9f5c-14fa-4dc0-99a7-bad6790111eb"
      },
      "cell_type": "code",
      "source": [
        "##### Dense 4 #####\n",
        "denselayer2_inputs = act5_outs\n",
        "\n",
        "###### TODO : Declare the last Dense layer #######\n",
        "\n",
        "end_points['FC'] = denselayer2_outs\n",
        "print(denselayer2_outs.shape)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fwreyOKjIYak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26f00460-41a1-46c5-cf4d-8655d256a1e7"
      },
      "cell_type": "code",
      "source": [
        "##### Final Activation #####\n",
        "finalact_inputs = denselayer2_outs\n",
        "finalact = Activation(finalact_inputs, 1)\n",
        "finalact_outs = finalact.forward_pass()\n",
        "end_points['finalact'] = finalact_outs\n",
        "\n",
        "print(\"Final Probabilities:\", end_points['finalact'])\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Probabilities: [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zVUXQvjawvVG",
        "colab_type": "code",
        "outputId": "65b8e23d-b407-4019-d275-2b49bcdb0138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "index = np.argmax(finalact_outs)\n",
        "predicted_class = class_names[index]\n",
        "print(\"Predicted Class:\", predicted_class)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class: frog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6QUKvSa9HK8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Pre Trained Model Weights\n",
        "\n",
        "Load pre trained model weights, trained on CIFAR 10 dataset"
      ]
    },
    {
      "metadata": {
        "id": "06JqhahZG3Wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loader(input_weights_file):\n",
        "  weights = pk.load(open(input_weights_file, 'rb'))\n",
        "  n_weights = {}\n",
        "  for layer_name in weights:\n",
        "    w = weights[layer_name]\n",
        "    if not (len(w) == 0):\n",
        "      if 'conv' in layer_name:\n",
        "        n_weights[layer_name] = np.array(w[0]).T\n",
        "      if 'dense' in layer_name:\n",
        "        n_weights[layer_name] = w[0]\n",
        "  return n_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1esTAmXJO0DF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxJt5QgXTUck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca27e265-d071-4bc4-b07c-1b705b434f4d"
      },
      "cell_type": "code",
      "source": [
        "filename = 'CIFAR_weights_rolled'\n",
        "m_weights = loader(filename)\n",
        "\n",
        "### Load pre trained weights for the network ###\n",
        "convlayer1_kernels = m_weights['conv2d_1']\n",
        "convlayer2_kernels = m_weights['conv2d_2']\n",
        "convlayer3_kernels = m_weights['conv2d_3']\n",
        "convlayer4_kernels = m_weights['conv2d_4']\n",
        "denselayer1_weights = np.array(m_weights['dense_1'])\n",
        "denselayer2_weights = np.array(m_weights['dense_2'])\n",
        "\n",
        "print(convlayer1_kernels.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 3, 3, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YKPbdmjbdgXD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**References**:\n",
        "\n",
        "[1] http://cs231n.github.io/ \n",
        "\n",
        "[2] http://timdettmers.com/2015/03/26/convolution-deep-learning/\n",
        "\n",
        "[3] https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0"
      ]
    }
  ]
}